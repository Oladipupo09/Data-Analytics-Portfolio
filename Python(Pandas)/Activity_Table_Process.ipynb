{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Table Creation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the files required in creating the Activity Table\n",
    "con = pd.read_excel('Source_File_Updated.xlsx','Contracts')\n",
    "sps_c = pd.read_excel('Source_File_Updated.xlsx','Sps Contracts')\n",
    "lp = pd.read_excel('Source_File_Updated.xlsx','Last payments')\n",
    "crmcon = pd.read_excel('Source_File_Updated.xlsx','CRM contracts')\n",
    "p_period = pd.read_excel('Source_File_Updated.xlsx','Contracts per PaidPeriod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalizes the datetime format into an absolute date format. i.e It converts the decimal entries to Zero\n",
    "#sps_c['activation_start'] = pd.to_datetime(sps_c['activation_start']).dt.normalize()\n",
    "sps_c['activation_end'] = pd.to_datetime(sps_c['activation_end']).dt.normalize()\n",
    "lp['activation_end'] = pd.to_datetime(lp['activation_end'], errors = 'coerce').dt.normalize()\n",
    "con['ContractCreation'] = pd.to_datetime(con['ContractCreation']).dt.normalize()\n",
    "#lp['payment_date'] = pd.to_datetime(lp['payment_date']).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joins the required columns needed to prepare the Table, using the Sps contracts file as the Primary (A) table \n",
    "\n",
    "#sps3 = pd.merge(sps1, sps2[['Contract','activation_end']], how='left', on='Contract')\n",
    "\n",
    "\n",
    "#first_join = con.merge(sps_c, how='left', on='Contract').merge(lp[['Contract','activation_end']],how='left', on='Contract')\n",
    "#.merge(crmcon[['id','CRMcontract']],how='left', left_on='Contract', right_on='id')\n",
    "#.merge(p_period[['Contract','PaidPeriods']],how='left', on='Contract')\n",
    "\n",
    "\n",
    "#df1.merge(df2,on='name').merge(df3,on='name')\n",
    "\n",
    "#This is the one that works..............................\n",
    "first_join = pd.merge(pd.merge(pd.merge(pd.merge(sps_c, con, how='left', on='Contract'),lp[['Contract','payment_date','activation_end']],how='left', on='Contract'),\n",
    "crmcon[['id','CRMcontract']],how='left', left_on='Contract', right_on='id'),p_period[['Contract','PaidPeriods']],how='left', on='Contract')\n",
    "\n",
    "\n",
    "#first_join.columns = ['Contract','ReportDate','SaleCH','generation','type','LTOperiod','LTOunits','ContractCreation','SpsId',\n",
    "                     #'Activation_Start', 'Activation_End','Reference_Activation_End','id','CRMcontract','PaidPeriods']\n",
    "\n",
    "\n",
    "#first_join\n",
    "\n",
    "#pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rename the required Date columns respectively for better identification\n",
    "first_join = first_join.rename(columns = {'activation_start': 'Sps_Activation_Start', 'activation_end_x': 'Sps_Activation_End', 'payment_date': 'LastPayment_Date',\n",
    "                                          'activation_end_y': 'LastPayment_Activation_End'}, inplace = False)\n",
    "\n",
    "\n",
    "\n",
    "#first_join[\"max_activation_end\"] = first_join[[\"Activation_End\",\"Reference_Activation_End\"]].max(axis=1)\n",
    "\n",
    "#first_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an extra date column that picks the maximium date between the Sps Activation End & Last Payment activation end\n",
    "first_join[\"Reference_Activation_End\"] = first_join[[\"Sps_Activation_End\",\"LastPayment_Activation_End\"]].max(axis=1)\n",
    "#first_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the column headers from small caps & init caps into full caps\n",
    "\n",
    "first_join.columns = ['contract','sps_id','sps_activation_start','sps_activation_end','report_date','sales_channel','generation','type',\n",
    "                       'lto_period','lto_units','contractcreation','lastpayment_date','lastpayment_activation_end','id','crmcontract',\n",
    "                       'paid_periods','reference_activation_end']\n",
    "\n",
    "\n",
    "#Creates another table that selects only the required columns from the existing table and arranges the columns in desired order \n",
    "\n",
    "second_join = first_join[['report_date','contract','contractcreation','sales_channel','generation','sps_id','crmcontract',\n",
    "                          'type','lto_period','lto_units','sps_activation_start','reference_activation_end','lastpayment_date','paid_periods']]\n",
    "\n",
    "\n",
    "\n",
    "#second_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-2b6ea11ca86c>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_join['outage_days'] = (second_join['reference_activation_end'] - to_day).dt.days\n"
     ]
    }
   ],
   "source": [
    "#Creates a new column that calculates Outage Days as Activation End Date - Reference Date\n",
    "#It first of all passes today's date into a variable named to_day and then iterates through the whole REFERENCE_ACTIVATION_END\n",
    "#column to get the days difference between the Activation End Date & Reference Date\n",
    "import datetime as date\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "today = pd.to_datetime('today').normalize()\n",
    "\n",
    "to_day = today - timedelta(days=9)\n",
    "\n",
    "second_join['outage_days'] = (second_join['reference_activation_end'] - to_day).dt.days\n",
    "\n",
    "\n",
    "#second_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olawale.falodun\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#Converting specific column(s) datatypes\n",
    "\n",
    "second_join[['crmcontract','lto_period','paid_periods','outage_days']] = second_join[['crmcontract','lto_period','paid_periods','outage_days']].apply(np.int64)\n",
    "\n",
    "#second_join.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-11295ec57881>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_join[\"old_active_status\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "#Creates an extra column to indicate the active status of a contract by manipulating the Outage Days \n",
    "second_join[\"old_active_status\"] = np.where(\n",
    "   (second_join.outage_days > -60), \n",
    "   \"Active\", \n",
    "   \"Churn\"\n",
    "    )\n",
    "\n",
    "#second_join.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an extra column to indicate the LIGHT status of a contract by manipulating the Outage Days\n",
    "second_join[\"light_status\"] = np.where(\n",
    "   (second_join.outage_days >= 0),\n",
    "   \"InLight\", \n",
    "   \"InDark\"\n",
    "    )\n",
    "\n",
    "#second_join.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Churn Check\n",
    "#second_join[second_join['OUTAGE_DAYS'] == -60]\n",
    "\n",
    "#second_join[second_join['STATUS'] == 'Retrieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an extra column to indicate the STATUS of a contract by manipulating the Outage Days\n",
    "second_join['status'] = (\n",
    "    np.where(\n",
    "        second_join['outage_days'] > -11, \n",
    "        'Paid', \n",
    "        np.where(second_join['outage_days'] < -40, \n",
    "                 'Retrieval',\n",
    "                np.where(second_join['outage_days'] < -10, \n",
    "                        'Recovery', 'Unavailable'))))\n",
    "\n",
    "#second_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column that Manipulates the identification of LCP and Customer Category\n",
    "\n",
    "filters = [\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'LEGACY') & (second_join.type == 'LTO') & (second_join.lto_period == 1800),\n",
    "   (second_join.sales_channel == 'AIRTEL_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'OUTRIGHT') & (second_join.lto_period == 1),\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'LEGACY') & (second_join.type == 'LTO') & (second_join.lto_period == 1500),\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'LTO') & (second_join.lto_period == 48),\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'LTO') & (second_join.lto_period == 1800),\n",
    "   (second_join.sales_channel == 'AIRTEL_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'LTO') & (second_join.lto_period == 24),\n",
    "   (second_join.sales_channel == 'AIRTEL_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'LTO') & (second_join.lto_period == 12),\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'UNIFIED') & (second_join.type == 'OUTRIGHT') & (second_join.lto_period == 1),\n",
    "   (second_join.sales_channel == 'MTN_NG') & (second_join.generation == 'LEGACY') & (second_join.type == 'LTO') & (second_join.lto_period == -1),\n",
    "   (second_join.lto_period == second_join.paid_periods)\n",
    "]\n",
    "values = ['MTN-LEGACY','OWNER','MTN-LEGACY','MTN-UNIFIED','MTN-UNIFIED','LCP','LCP','OWNER','OWNER','OWNER']\n",
    "\n",
    "second_join[\"customer_category\"] = np.select(filters, values, default='AIRTEL-UNIFIED')\n",
    "\n",
    "#second_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_join['lastpayment_date'] = second_join['lastpayment_date'].fillna('1900-01-01')\n",
    "second_join['sps_activation_start'] = second_join['sps_activation_start'].fillna('1900-01-01')\n",
    "second_join['reference_activation_end'] = second_join['reference_activation_end'].fillna('1900-01-01')\n",
    "second_join['report_date'] = second_join['report_date'].fillna('1900-01-01')\n",
    "second_join['type'] = second_join['type'].fillna('null')\n",
    "second_join['lto_units'] = second_join['lto_units'].fillna('null')\n",
    "second_join['sales_channel'] = second_join['sales_channel'].fillna('null')\n",
    "second_join['contractcreation'] = second_join['contractcreation'].fillna('1900-01-01')\n",
    "second_join['generation'] = second_join['generation'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This helps to replace wrong state entries with the correct ones\n",
    "#ng_location = pd.read_csv('NG_Location_File.csv')\n",
    "\n",
    "###This is to replace entries for a single column\n",
    "#ng_location[\"Customer: Billing State/Province\"].replace({\"Abuja\": \"FCT\", \"Bornu\": \"Borno\", \"Cross River \": \"Cross River\", \"Ebonyi \": \"Ebonyi\"}, inplace=True)\n",
    "\n",
    "\n",
    "##This is to replace for the entire Data Frame\n",
    "#ng_location = ng_location.replace(['Abuja','Bornu','Cross River ','Ebonyi ','Federal Capital Territory','Federal Capital Territory (FCT)','Akiti'],['FCT','Borno','Cross River','Ebonyi','FCT','FCT','Ekiti'])\n",
    "\n",
    "#ng_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ng_location = pd.read_csv('NG_Location_File.csv')\n",
    "ng_location = ng_location.replace(['Abuja','Bornu','Cross River ','Ebonyi ','Federal Capital Territory','Federal Capital Territory (FCT)','Akiti'],['FCT','Borno','Cross River','Ebonyi','FCT','FCT','Ekiti'])\n",
    "ng_location['State'] = ng_location['State'].fillna(ng_location['Customer: Billing State/Province'])\n",
    "ng_location['State'] = ng_location['State'].fillna(ng_location['Mailing State/Province'])\n",
    "ng_location['State'] = ng_location['State'].fillna('Unknown')\n",
    "ng_location['Local Government'] = ng_location['Local Government'].fillna('null')\n",
    "ng_location['Location (Longitude)'] = ng_location['Location (Longitude)'].fillna(0)\n",
    "ng_location['Location (Latitude)'] = ng_location['Location (Latitude)'].fillna(0)\n",
    "\n",
    "state_region = pd.read_excel(\"State_Region.xlsx\")\n",
    "\n",
    "ng_location_prior = pd.merge(ng_location, state_region, how='left', on='State')\n",
    "\n",
    "ng_location_complete = ng_location_prior[[\"Full SFID\",\"Contract Id\",\"Local Government\",\"State\",\"Region\",\"Location (Longitude)\",\"Location (Latitude)\"]]\n",
    "\n",
    "ng_location_complete = ng_location_complete.rename(columns = {'Full SFID': 'contract'}, inplace = False)\n",
    "\n",
    "second_join = pd.merge(second_join, ng_location_complete[['contract','Local Government','State','Region','Location (Longitude)','Location (Latitude)']], how='left', on='contract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_join['State'] = second_join['State'].fillna('Unknown')\n",
    "second_join['Local Government'] = second_join['Local Government'].fillna('Unknown')\n",
    "second_join['Location (Longitude)'] = second_join['Location (Longitude)'].fillna(0)\n",
    "second_join['Location (Latitude)'] = second_join['Location (Latitude)'].fillna(0)\n",
    "second_join['Region'] = second_join['Region'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 164140 entries, 0 to 164139\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   report_date               164140 non-null  object \n",
      " 1   contract                  164140 non-null  object \n",
      " 2   contractcreation          164140 non-null  object \n",
      " 3   sales_channel             164140 non-null  object \n",
      " 4   generation                164140 non-null  object \n",
      " 5   sps_id                    164140 non-null  int64  \n",
      " 6   crmcontract               164140 non-null  int64  \n",
      " 7   type                      164140 non-null  object \n",
      " 8   lto_period                164140 non-null  int64  \n",
      " 9   lto_units                 164140 non-null  object \n",
      " 10  sps_activation_start      164140 non-null  object \n",
      " 11  reference_activation_end  164140 non-null  object \n",
      " 12  lastpayment_date          164140 non-null  object \n",
      " 13  paid_periods              164140 non-null  int64  \n",
      " 14  outage_days               164140 non-null  int64  \n",
      " 15  old_active_status         164140 non-null  object \n",
      " 16  light_status              164140 non-null  object \n",
      " 17  status                    164140 non-null  object \n",
      " 18  customer_category         164140 non-null  object \n",
      " 19  Local Government          164140 non-null  object \n",
      " 20  State                     164140 non-null  object \n",
      " 21  Region                    164140 non-null  object \n",
      " 22  Location (Longitude)      164140 non-null  float64\n",
      " 23  Location (Latitude)       164140 non-null  float64\n",
      "dtypes: float64(2), int64(5), object(17)\n",
      "memory usage: 31.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Filtering with single column\n",
    "#second_join[(second_join['OUTAGE_DAYS'] == -3) | (second_join['OUTAGE_DAYS'] == -18) | (second_join['OUTAGE_DAYS'] == -34)]\n",
    "\n",
    "#second_join[second_join['OUTAGE_DAYS'] == -34]\n",
    "\n",
    "#second_join.isnull().sum().sort_values(ascending = False)\n",
    "second_join.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to lumos_bi_ng database:  ('lumos_bi_ng',)\n",
      "inserting into activity....\n",
      "Activity Table completely updated\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = msql.connect(host='localhost', \n",
    "                           database='lumos_bi_ng', user='root', \n",
    "                           password='', port='3308')\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to lumos_bi_ng database: \", record)\n",
    "        #cursor.execute('DROP TABLE IF EXISTS activity;')\n",
    "        #cursor.execute(\"TRUNCATE TABLE activity\")\n",
    "        #print('Activity Table Truncated....')\n",
    "        #print('Re-Creating Activity Table....')\n",
    "        #cursor.execute(\"CREATE TABLE activity (report_date DATE NULL,contract VARCHAR(30) NULL,contractcreation DATE NULL,sales_channel VARCHAR(20) NULL,generation VARCHAR(20) NULL,sps_id INT NULL,crmcontract BIGINT NULL,type VARCHAR(20) NULL,lto_period BIGINT NULL,lto_units VARCHAR(20) NULL,sps_activation_start DATETIME NULL,reference_activation_end DATE NULL,lastpayment_date DATETIME NULL,paid_periods BIGINT NULL,outage_days BIGINT NULL,old_active_status VARCHAR(20) NULL,light_status VARCHAR(20) NULL,status VARCHAR(20) NULL)\")\n",
    "        print(\"inserting into activity....\")\n",
    "        for i,row in second_join.iterrows():\n",
    "            sql = \"INSERT INTO lumos_bi_ng.activity VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "            #print(\"Record inserted\")\n",
    "            # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "            conn.commit()\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "    \n",
    "print (\"Activity Table completely updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1060 (42S21): Duplicate column name 'customer_category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    515\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             self._cmysql.query(query,\n\u001b[0m\u001b[0;32m    517\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Duplicate column name 'customer_category'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b22aeabd25c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ALTER TABLE lumos_bi_ng.activity ADD COLUMN customer_category VARCHAR(45) NULL AFTER status'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mysql\\connector\\cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[0m\u001b[0;32m    270\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                                          raw_as_string=self._raw_as_string)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    519\u001b[0m                                query_attrs=self._query_attrs)\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n\u001b[0m\u001b[0;32m    522\u001b[0m                                              sqlstate=exc.sqlstate)\n\u001b[0;32m    523\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1060 (42S21): Duplicate column name 'customer_category'"
     ]
    }
   ],
   "source": [
    "#cursor.execute('ALTER TABLE lumos_bi_ng.activity ADD COLUMN customer_category VARCHAR(45) NULL AFTER status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
